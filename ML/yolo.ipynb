{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x000001B8E55F01D0>\n",
      "NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b60306",
   "metadata": {},
   "source": [
    "3 = digits low\n",
    "17 = all mid\n",
    "22 = all high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dfb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO #i boni 17 21\n",
    "#model = YOLO('yolov8n.pt')   # choose a pretrained model\n",
    "model = YOLO(r'C:\\Users\\Cesare\\Desktop\\chitarra\\runs\\detect\\train22\\weights\\last.pt')   # choose a pretrained model\n",
    "model.train(data='data.yaml', epochs=200, imgsz=1080, batch=16, verbose=False, plots=False, resume=True, cfg='hyp.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68e72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.193 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.191  Python-3.11.9 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=prova_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=200, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=31\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    757357  ultralytics.nn.modules.head.Detect           [31, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,016,893 parameters, 3,016,877 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING imgsz=[200] must be multiple of max stride 32, updating to [224]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 44.115.5 MB/s, size: 3.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Cesare\\Desktop\\chitarra\\single_digit_dataset\\labels\\train.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3.01.9 MB/s, size: 3.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Cesare\\Desktop\\chitarra\\single_digit_dataset\\labels\\val... 1000 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 1100.0it/s 0.9s1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Cesare\\Desktop\\chitarra\\single_digit_dataset\\labels\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000286, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      13.3G     0.8931      4.478      1.021         18        224: 100% ━━━━━━━━━━━━ 63/63 9.8it/s 6.5s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 11.2it/s 2.9s0.2s\n",
      "                   all       1000       1000     0.0341     0.0391     0.0214     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100     0.355G     0.6624      3.752     0.9334         13        224: 100% ━━━━━━━━━━━━ 63/63 11.7it/s 5.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.383     0.0922      0.119      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100     0.373G     0.6257      3.101     0.9372         10        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.225      0.443      0.266      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100     0.391G     0.5914      2.648     0.9449         10        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.3it/s 3.9s0.1s\n",
      "                   all       1000       1000      0.367      0.481      0.387       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100     0.406G     0.5661      2.381     0.9319         13        224: 100% ━━━━━━━━━━━━ 63/63 11.6it/s 5.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.2it/s 3.9s0.1s\n",
      "                   all       1000       1000      0.344       0.61      0.526      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100     0.424G     0.5433      2.224     0.9382         15        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.355      0.722      0.591       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100     0.441G     0.5348      2.051     0.9335         19        224: 100% ━━━━━━━━━━━━ 63/63 11.8it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000       0.61      0.724      0.751      0.706\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100     0.459G     0.5082      1.916     0.9283         13        224: 100% ━━━━━━━━━━━━ 63/63 11.6it/s 5.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.668      0.769      0.815      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100     0.475G     0.4835      1.759     0.9187         13        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.735      0.798       0.87      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100     0.492G     0.4569      1.678     0.9039         13        224: 100% ━━━━━━━━━━━━ 63/63 12.6it/s 5.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.851      0.857      0.927      0.895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      0.51G     0.4431      1.594     0.8991         13        224: 100% ━━━━━━━━━━━━ 63/63 12.5it/s 5.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.2it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.919      0.856      0.948      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100     0.527G     0.4452      1.546     0.9047         14        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.936      0.882      0.957      0.917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100     0.543G     0.4239      1.437     0.8995         18        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.952      0.941      0.979      0.936\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100     0.561G     0.4326      1.392     0.9022         19        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.958      0.935      0.986      0.942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100     0.578G      0.408      1.304     0.8911         17        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.1it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.975      0.951      0.989      0.957\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100     0.596G     0.4096      1.314     0.8971         22        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.979      0.983      0.994      0.959\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100     0.611G     0.4096      1.244     0.8903         15        224: 100% ━━━━━━━━━━━━ 63/63 13.1it/s 4.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.966      0.973      0.993      0.968\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100     0.629G     0.3712      1.232     0.8843         12        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.1it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.982      0.984      0.994      0.966\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100     0.646G     0.3673      1.156     0.8785         14        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.2it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.982      0.986      0.994      0.966\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100     0.662G     0.3722      1.188     0.8869          9        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.8it/s 3.6s0.1s\n",
      "                   all       1000       1000       0.98      0.974      0.993      0.959\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      0.68G     0.3575      1.112     0.8781         10        224: 100% ━━━━━━━━━━━━ 63/63 13.0it/s 4.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000       0.98      0.979      0.994      0.971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100     0.697G     0.3613      1.097     0.8748         21        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.982       0.98      0.994      0.977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100     0.715G      0.358      1.083     0.8808         15        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.1it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.985      0.985      0.995      0.977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      0.73G      0.345      1.068     0.8738         13        224: 100% ━━━━━━━━━━━━ 63/63 13.3it/s 4.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.981      0.986      0.994      0.972\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100     0.748G      0.348      1.056     0.8803         20        224: 100% ━━━━━━━━━━━━ 63/63 12.6it/s 5.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.989      0.984      0.995      0.976\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100     0.766G     0.3343      1.004     0.8714         15        224: 100% ━━━━━━━━━━━━ 63/63 12.7it/s 5.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.988      0.991      0.995      0.978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100     0.783G      0.326      1.048     0.8744         13        224: 100% ━━━━━━━━━━━━ 63/63 13.2it/s 4.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.984      0.987      0.995      0.982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100     0.799G     0.3259      0.961     0.8651         14        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.987      0.994      0.995      0.978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100     0.816G     0.3328     0.9806      0.876         14        224: 100% ━━━━━━━━━━━━ 63/63 12.8it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.1it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.991      0.989      0.995      0.981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100     0.834G     0.3239     0.9345     0.8636         14        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.989      0.994      0.995       0.98\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100     0.852G     0.3288     0.9681      0.869         21        224: 100% ━━━━━━━━━━━━ 63/63 13.1it/s 4.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.6s0.1s\n",
      "                   all       1000       1000       0.99      0.995      0.995      0.981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100     0.867G     0.3161     0.9795     0.8725         10        224: 100% ━━━━━━━━━━━━ 63/63 13.1it/s 4.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.1it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.988      0.994      0.995      0.981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100     0.885G     0.3082     0.9515     0.8658         15        224: 100% ━━━━━━━━━━━━ 63/63 12.7it/s 5.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.2it/s 3.5s0.1s\n",
      "                   all       1000       1000      0.987      0.996      0.995      0.982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100     0.902G     0.3063     0.9512     0.8706         16        224: 100% ━━━━━━━━━━━━ 63/63 13.0it/s 4.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 9.0it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.989      0.993      0.995       0.98\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      0.92G     0.3131     0.9446     0.8658         18        224: 100% ━━━━━━━━━━━━ 63/63 12.9it/s 4.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.8it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.992      0.994      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100     0.936G     0.3062     0.9019     0.8675         11        224: 100% ━━━━━━━━━━━━ 63/63 12.7it/s 5.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.2it/s 3.9s0.1s\n",
      "                   all       1000       1000      0.989      0.997      0.995      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100     0.953G     0.3011     0.9107     0.8593         13        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.987      0.994      0.995      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100     0.971G     0.2999      0.891     0.8608         19        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.992      0.995      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100     0.986G     0.2951        0.9      0.864         16        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.991      0.993      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100         1G     0.2777     0.8732     0.8503         13        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.992      0.996      0.995      0.984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      1.02G     0.2862     0.8587      0.854         16        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.991      0.995      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      1.04G     0.2845     0.8662     0.8527         12        224: 100% ━━━━━━━━━━━━ 63/63 11.6it/s 5.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.3it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.992      0.996      0.995      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      1.06G      0.287     0.8834     0.8589         16        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000       0.99      0.993      0.995      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      1.07G     0.2912     0.8718      0.855         19        224: 100% ━━━━━━━━━━━━ 63/63 12.6it/s 5.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.988      0.999      0.995      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      1.09G     0.2868     0.8777     0.8615         17        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.998      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      1.11G     0.2794     0.8359     0.8597         15        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.993      0.996      0.995      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      1.12G     0.2806      0.833     0.8602         15        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.991      0.998      0.995      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      1.14G     0.2731     0.7937      0.852         16        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.992      0.996      0.995      0.979\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      1.16G     0.2754     0.7914     0.8561         16        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.991      0.997      0.995      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      1.18G     0.2787     0.8124     0.8619         14        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.993      0.996      0.995       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      1.19G     0.2749      0.817     0.8603         18        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.994      0.995      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      1.21G     0.2731     0.8051     0.8563         19        224: 100% ━━━━━━━━━━━━ 63/63 12.5it/s 5.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.995      0.996      0.995      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      1.23G     0.2722     0.8158     0.8538         16        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.993      0.999      0.995      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      1.24G     0.2605     0.7794     0.8546         13        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.9it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.996      0.997      0.995      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      1.26G     0.2581     0.8244     0.8548         12        224: 100% ━━━━━━━━━━━━ 63/63 11.9it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.994      0.996      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      1.28G     0.2619     0.7889     0.8615          6        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.995      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      1.29G     0.2595     0.7659     0.8499         18        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.997      0.995      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      1.31G     0.2622       0.78     0.8527         11        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.992      0.997      0.995      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      1.33G     0.2685     0.8256      0.852         15        224: 100% ━━━━━━━━━━━━ 63/63 11.8it/s 5.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.993      0.997      0.995      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      1.35G      0.255      0.758     0.8515         16        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.993      0.996      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      1.36G     0.2553     0.7643     0.8538         14        224: 100% ━━━━━━━━━━━━ 63/63 11.9it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.991      0.996      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      1.38G     0.2539     0.7654     0.8507         14        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.993      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100       1.4G     0.2456     0.7473     0.8471         13        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.998      0.995       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      1.41G     0.2457     0.7358     0.8494         13        224: 100% ━━━━━━━━━━━━ 63/63 12.4it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.8it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.994      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      1.43G     0.2488     0.7934     0.8531         16        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.993      0.996      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      1.45G     0.2491     0.7515     0.8516         16        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.991      0.997      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      1.46G     0.2415     0.7521     0.8451         13        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.8it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.997      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      1.48G     0.2482     0.7496     0.8482         11        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.989      0.998      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100       1.5G     0.2459     0.7411     0.8515         14        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      1.52G     0.2455     0.7445     0.8475         15        224: 100% ━━━━━━━━━━━━ 63/63 12.4it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.995      0.997      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      1.53G     0.2431     0.7442     0.8476         11        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.998      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      1.55G     0.2456     0.7168     0.8417         13        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      1.57G     0.2447     0.7398     0.8451          7        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.999      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      1.58G     0.2307     0.7261     0.8514         21        224: 100% ━━━━━━━━━━━━ 63/63 11.9it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100       1.6G     0.2365     0.7401     0.8522         15        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.996      0.997      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      1.62G     0.2387     0.7125     0.8455         12        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.994      0.997      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      1.64G     0.2354     0.7273     0.8431         17        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      1.65G     0.2361     0.7226     0.8452         15        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      1.67G     0.2292     0.6997     0.8413          9        224: 100% ━━━━━━━━━━━━ 63/63 11.4it/s 5.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.996      0.994      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      1.69G     0.2191     0.6982     0.8436         14        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.997      0.995      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      1.71G      0.232     0.7066     0.8435         13        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      1.72G     0.2202     0.6984     0.8387         13        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.985      0.998      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      1.74G       0.23     0.6716      0.848         17        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.996      0.998      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      1.76G     0.2229     0.6908     0.8406         15        224: 100% ━━━━━━━━━━━━ 63/63 11.9it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.998      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      1.77G      0.229     0.6831     0.8485         14        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.994      0.997      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      1.79G     0.2199     0.6635     0.8371         18        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.995      0.999      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      1.81G     0.2179     0.7028     0.8465         10        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.994      0.999      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      1.82G     0.2176     0.6683     0.8419         10        224: 100% ━━━━━━━━━━━━ 63/63 12.5it/s 5.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.995      0.999      0.995      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      1.84G     0.2177     0.6892     0.8514         13        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      1.86G     0.2134     0.6563     0.8405         16        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.995      0.998      0.995      0.994\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      1.88G     0.1748      0.388     0.8015          8        224: 100% ━━━━━━━━━━━━ 63/63 12.1it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.997      0.999      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      1.89G     0.1646     0.3572     0.7983          8        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.998      0.999      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      1.91G     0.1602     0.3447     0.7962          8        224: 100% ━━━━━━━━━━━━ 63/63 12.4it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.7it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.998      0.999      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      1.93G     0.1601     0.3374     0.8025          8        224: 100% ━━━━━━━━━━━━ 63/63 12.4it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      1.94G     0.1573     0.3428     0.7928          8        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      1.96G     0.1574      0.336     0.7971          8        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.4it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      1.98G     0.1547     0.3296     0.8008          8        224: 100% ━━━━━━━━━━━━ 63/63 11.8it/s 5.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      1.99G     0.1561     0.3352      0.795          8        224: 100% ━━━━━━━━━━━━ 63/63 12.2it/s 5.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.6it/s 3.7s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      2.01G     0.1523     0.3253     0.7977          8        224: 100% ━━━━━━━━━━━━ 63/63 12.3it/s 5.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.5it/s 3.8s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      2.03G     0.1486     0.3257     0.7924          8        224: 100% ━━━━━━━━━━━━ 63/63 12.0it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.8it/s 3.6s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "\n",
      "100 epochs completed in 0.256 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics 8.3.191  Python-3.11.9 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "Model summary (fused): 72 layers, 3,011,693 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 10.9it/s 2.9s0.1s\n",
      "                   all       1000       1000      0.998          1      0.995      0.994\n",
      "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 1.1ms postprocess per image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000020C3F9F1D50>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1., 1., 1., ..., 1., 1., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 0.]], shape=(31, 1000)), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.35978836, 0.35978836, 0.5073457 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11721612, 0.11721612, 0.18621199, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.13302752, 0.13302752, 0.20253969, ..., 0.47769429, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.135     , 0.135     , 0.1733266 , ..., 0.26367118, 0.        ,\n",
       "        0.        ],\n",
       "       [0.12201592, 0.12201592, 0.16310259, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.14388489, 0.14388489, 0.21894085, ..., 0.07074576, 0.        ,\n",
       "        0.        ]], shape=(31, 1000)), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.21935484, 0.21935484, 0.33989498, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.06225681, 0.06225681, 0.1026647 , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.07125307, 0.07125307, 0.11268103, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.07238606, 0.07238606, 0.09488648, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.06497175, 0.06497175, 0.08879243, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.07751938, 0.07751938, 0.12292734, ..., 1.        , 1.        ,\n",
       "        1.        ]], shape=(31, 1000)), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.31379656, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 0.15185556, 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.03667   , 0.        ,\n",
       "        0.        ]], shape=(31, 1000)), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.9941867385987467)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.995     , 0.995     , 0.995     , 0.995     , 0.99318112,\n",
       "       0.99007001, 0.99213629, 0.995     , 0.995     , 0.995     ,\n",
       "       0.995     , 0.995     , 0.99183249, 0.99055599, 0.99157131,\n",
       "       0.995     , 0.98764045, 0.995     , 0.995     , 0.995     ,\n",
       "       0.995     , 0.995     , 0.995     , 0.995     , 0.995     ,\n",
       "       0.995     , 0.995     , 0.995     , 0.995     , 0.995     ,\n",
       "       0.995     ])\n",
       "names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30'}\n",
       "nt_per_class: array([34, 32, 29, 32, 43, 40, 30, 43, 28, 28, 25, 43, 38, 21, 27, 34, 27,\n",
       "       31, 22, 37, 33, 41, 34, 32, 34, 37, 30, 35, 27, 23, 30])\n",
       "nt_per_image: array([34, 32, 29, 32, 43, 40, 30, 43, 28, 28, 25, 43, 38, 21, 27, 34, 27,\n",
       "       31, 22, 37, 33, 41, 34, 32, 34, 37, 30, 35, 27, 23, 30])\n",
       "results_dict: {'metrics/precision(B)': 0.9978090926108187, 'metrics/recall(B)': 0.9999924074030438, 'metrics/mAP50(B)': 0.9950000000000002, 'metrics/mAP50-95(B)': 0.9940963762208297, 'fitness': 0.9941867385987467}\n",
       "save_dir: WindowsPath('runs/detect/train3')\n",
       "speed: {'preprocess': 0.03119390000938438, 'inference': 0.3898706999607384, 'loss': 0.0001963000395335257, 'postprocess': 1.119936900009634}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO #i boni 17 21\n",
    "model = YOLO('yolov8n.pt')   # choose a pretrained model\n",
    "model.train(data='prova_data.yaml', epochs=100, imgsz=200, batch=16, verbose=False, plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16769249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING imgsz=[3000] must be multiple of max stride 32, updating to [3008]\n",
      "image 1/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\0_sl.jpg: 288x3008 2 14s, 1 18, 3 23s, 12 24s, 12 25s, 49.8ms\n",
      "image 2/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\a.png: 448x3008 1 2, 7 5s, 1 6, 3 7s, 2 8s, 56.9ms\n",
      "image 3/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\b.png: 256x3008 2 1s, 12 12s, 4 13s, 10 14s, 9 15s, 1 17, 1 19, 67.5ms\n",
      "image 4/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\c.png: 704x3008 5 12s, 2 14s, 4 15s, 53.3ms\n",
      "image 5/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\d.png: 576x3008 4 12s, 5 14s, 42.4ms\n",
      "image 6/6 c:\\Users\\Cesare\\Desktop\\chitarra\\prove_songsterr_inverted\\e.png: 1440x3008 2 5s, 1 9, 47.5ms\n",
      "Speed: 6.9ms preprocess, 52.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1440, 3008)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "model = YOLO(\"runs/detect/train3/weights/best.pt\")\n",
    "\n",
    "input_folder = \"prove_songsterr\"\n",
    "output_folder = \"prove_songsterr_inverted\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            inverted_img = cv2.bitwise_not(img)\n",
    "            cv2.imwrite(os.path.join(output_folder, filename), inverted_img)\n",
    "\n",
    "# Run prediction on a folder of test images\n",
    "results = model.predict(source=\"prove_songsterr_inverted\", conf=0.25, imgsz=3000)\n",
    "\n",
    "for r in results:\n",
    "    r.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
